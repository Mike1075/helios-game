from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import os
import json
import time
import asyncio
from typing import Optional, Dict, Any, List
from dotenv import load_dotenv
from openai import OpenAI
from supabase import create_client, Client
# Zepç›¸å…³å¯¼å…¥æš‚æ—¶æ³¨é‡Šï¼Œä½¿ç”¨ç®€å•å†…å­˜å­˜å‚¨
# from zep_python import Memory, Message as ZepMessage, User, Session

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

app = FastAPI(title="Helios Agent Core", version="0.1.0")

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆå§‹åŒ–æœåŠ¡å®¢æˆ·ç«¯
tongyi_client = OpenAI(
    api_key=os.getenv("TONGYI_API_KEY"),
    base_url=os.getenv("TONGYI_URL")
)

supabase: Client = create_client(
    os.getenv("SUPABASE_URL"),
    os.getenv("SUPABASE_SERVICE_KEY")
)

# æš‚æ—¶ç¦ç”¨Zepï¼Œä½¿ç”¨ç®€å•çš„å†…å­˜å­˜å‚¨
# zep_client = None  # ç¨åå®ç°

# æ•°æ®æ¨¡å‹
class ChatRequest(BaseModel):
    player_id: str
    message: str
    npc_id: Optional[str] = "auto"  # é»˜è®¤ä¸ºautoï¼Œè‡ªåŠ¨é€‰æ‹©NPC
    scene_id: str = "tavern"

class EchoRequest(BaseModel):
    player_id: str
    event_id: str

class ChatResponse(BaseModel):
    npc_id: str
    response: str
    timestamp: float
    belief_influenced: bool = False

class EchoResponse(BaseModel):
    attribution: str
    memory_evidence: List[str]
    timestamp: float

# NPCé…ç½®æ•°æ®
NPCS_CONFIG = {
    "guard_alvin": {
        "name": "è‰¾å°”æ–‡",
        "role": "åŸå«å…µ", 
        "core_motivation": "ç»´æŠ¤æ¸¯å£ç§©åºï¼Œä¿æŠ¤å¸‚æ°‘å®‰å…¨",
        "personality": "ä¸¥è°¨ã€æ­£ç›´ã€ç•¥æ˜¾åˆ»æ¿ä½†å†…å¿ƒå–„è‰¯",
        "belief_system": """
        worldview:
          - ç§©åºæ˜¯ç¤¾ä¼šå®‰å®šçš„åŸºç¡€
          - æ³•å¾‹é¢å‰äººäººå¹³ç­‰
          - å¤–æ¥è€…éœ€è¦æ ¼å¤–å…³æ³¨
        selfview:
          - æˆ‘æœ‰è´£ä»»ä¿æŠ¤è¿™é‡Œçš„æ°‘ä¼—
          - æˆ‘çš„èŒè´£å°±æ˜¯æˆ‘çš„è£èª‰
          - æˆ‘å¿…é¡»å…¬æ­£æ‰§æ³•
        values:
          - æ­£ä¹‰é«˜äºä¸ªäººæ„Ÿæƒ…
          - èŒè´£æ¯”ç”Ÿå‘½æ›´é‡è¦
          - ç§©åºèƒœè¿‡æ··ä¹±
        """
    },
    "wanderer_karin": {
        "name": "å¡ç³",
        "role": "æµæµªè€…",
        "core_motivation": "åœ¨è¿™ä¸ªå……æ»¡æ•Œæ„çš„ä¸–ç•Œä¸­ç”Ÿå­˜ä¸‹å»",
        "personality": "è­¦è§‰ã€æœºæ™ºã€è¡¨é¢å†·æ¼ ä½†æ¸´æœ›è¢«ç†è§£",
        "belief_system": """
        worldview:
          - ä¸–ç•Œå¯¹å¼±è€…å……æ»¡æ¶æ„
          - åªèƒ½ä¾é è‡ªå·±æ‰èƒ½ç”Ÿå­˜
          - ä¿¡ä»»åˆ«äººå°±æ˜¯è‡ªå¯»æ­»è·¯
        selfview:
          - æˆ‘å¿…é¡»æ—¶åˆ»ä¿æŒè­¦æƒ•
          - æˆ‘æ²¡æœ‰æœ‹å‹ï¼Œåªæœ‰åˆ©ç›Š
          - æˆ‘æ˜¯ä¸ªæ— å®¶å¯å½’çš„æµæµªè€…
        values:
          - ç”Ÿå­˜é«˜äºä¸€åˆ‡
          - è‡ªç”±èƒœè¿‡å®‰å…¨
          - ç‹¬ç«‹æ¯”ä¾èµ–æ›´å¯é 
        """
    },
    "scholar_thane": {
        "name": "å¡æ©", 
        "role": "å­¦è€…",
        "core_motivation": "è¿½å¯»å¤è€çš„æ™ºæ…§ä¸çœŸç†",
        "personality": "åšå­¦ã€å¥½å¥‡ã€æœ‰æ—¶è¿‡äºæ²‰è¿·äºç†è®º",
        "belief_system": """
        worldview:
          - çŸ¥è¯†æ˜¯ä¸–ç•Œä¸Šæœ€å®è´µçš„è´¢å¯Œ
          - çœŸç†å¾€å¾€éšè—åœ¨å¤è€çš„æ–‡çŒ®ä¸­
          - ç†è§£è¿‡å»èƒ½é¢„æµ‹æœªæ¥
        selfview:
          - æˆ‘æ˜¯æ™ºæ…§çš„è¿½æ±‚è€…
          - æˆ‘æœ‰ä¹‰åŠ¡ä¼ æ’­çŸ¥è¯†
          - æˆ‘å¸¸å¸¸æ²‰æµ¸åœ¨æ€è€ƒä¸­
        values:
          - æ™ºæ…§æ¯”è´¢å¯Œæ›´é‡è¦
          - çœŸç†èƒœè¿‡æ–¹ä¾¿çš„è°è¨€
          - å­¦ä¹ æ˜¯ç»ˆç”Ÿçš„ä½¿å‘½
        """
    }
}

# ç®€å•çš„å†…å­˜å­˜å‚¨ï¼Œæ›¿ä»£Zep
conversation_store = {}

# è¾…åŠ©å‡½æ•°
async def ensure_user_exists(user_id: str):
    """ç¡®ä¿ç”¨æˆ·å­˜åœ¨ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
    # ç®€åŒ–å®ç°ï¼Œåªæ˜¯ç¡®ä¿ç”¨æˆ·åœ¨æˆ‘ä»¬çš„å†…å­˜storeä¸­
    pass

async def get_conversation_history(session_id: str, limit: int = 10):
    """ä»å†…å­˜è·å–å¯¹è¯å†å²"""
    try:
        if session_id in conversation_store:
            history = conversation_store[session_id][-limit:]
            return history
        return []
    except Exception as e:
        print(f"è·å–å¯¹è¯å†å²å¤±è´¥: {e}")
        return []

async def save_conversation_to_memory(session_id: str, user_message: str, assistant_message: str):
    """ä¿å­˜å¯¹è¯åˆ°å†…å­˜"""
    try:
        if session_id not in conversation_store:
            conversation_store[session_id] = []
        
        conversation_store[session_id].extend([
            {"role": "user", "content": user_message},
            {"role": "assistant", "content": assistant_message}
        ])
        
        # ä¿æŒæœ€è¿‘20æ¡è®°å½•
        if len(conversation_store[session_id]) > 20:
            conversation_store[session_id] = conversation_store[session_id][-20:]
            
    except Exception as e:
        print(f"ä¿å­˜å¯¹è¯å¤±è´¥: {e}")

async def save_to_supabase(table: str, data: Dict):
    """ä¿å­˜æ•°æ®åˆ°Supabase"""
    try:
        result = supabase.table(table).insert(data).execute()
        return result.data
    except Exception as e:
        print(f"ä¿å­˜åˆ°Supabaseå¤±è´¥: {e}")
        return None

async def call_tongyi_llm(system_prompt: str, user_message: str, model: str = "qwen-plus"):
    """è°ƒç”¨é€šä¹‰åƒé—®LLM"""
    try:
        response = tongyi_client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ],
            max_tokens=1000,
            temperature=0.8
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"è°ƒç”¨é€šä¹‰åƒé—®å¤±è´¥: {e}")
        # è¿”å›fallbackå“åº”
        return f"*ç³»ç»Ÿç¹å¿™ï¼Œè¯·ç¨åå†è¯•* (é”™è¯¯: {str(e)})"

async def select_responding_npc(user_message: str, available_npcs: list) -> str:
    """åŸºäºç”¨æˆ·æ¶ˆæ¯å†…å®¹æ™ºèƒ½é€‰æ‹©æœ€åˆé€‚çš„NPCæ¥å“åº”"""
    try:
        # æ„å»ºNPCé€‰æ‹©æç¤ºè¯
        npc_descriptions = []
        for npc_id, npc_data in available_npcs:
            npc_descriptions.append(f"- {npc_id}: {npc_data['name']}({npc_data['role']}) - {npc_data['core_motivation']}")
        
        selection_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½å¯¹è¯è·¯ç”±å™¨ï¼Œè´Ÿè´£åˆ†æç”¨æˆ·æ¶ˆæ¯å¹¶é€‰æ‹©æœ€åˆé€‚çš„NPCæ¥å“åº”ã€‚

å¯é€‰çš„NPCè§’è‰²ï¼š
{chr(10).join(npc_descriptions)}

ç”¨æˆ·æ¶ˆæ¯ï¼š"{user_message}"

è¯·åŸºäºä»¥ä¸‹åŸåˆ™é€‰æ‹©æœ€åˆé€‚çš„NPCï¼š
1. æ¶ˆæ¯å†…å®¹ä¸NPCçš„è§’è‰²èŒè´£æœ€ç›¸å…³
2. NPCçš„æ€§æ ¼ç‰¹ç‚¹æœ€é€‚åˆå›åº”è¿™ç±»è¯é¢˜
3. NPCçš„æ ¸å¿ƒåŠ¨æœºä¸æ¶ˆæ¯ä¸»é¢˜æœ€åŒ¹é…

è¯·åªè¿”å›NPCçš„IDï¼ˆå¦‚ï¼šguard_alvinï¼‰ï¼Œä¸è¦åŒ…å«å…¶ä»–å†…å®¹ã€‚
"""
        
        selected_npc = await call_tongyi_llm(selection_prompt, user_message)
        selected_npc = selected_npc.strip()
        
        # éªŒè¯é€‰æ‹©æ˜¯å¦æœ‰æ•ˆ
        valid_npc_ids = [npc_id for npc_id, _ in available_npcs]
        if selected_npc in valid_npc_ids:
            return selected_npc
        else:
            # å¦‚æœAIè¿”å›æ— æ•ˆé€‰æ‹©ï¼Œé»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªNPC
            print(f"AIé€‰æ‹©äº†æ— æ•ˆçš„NPC: {selected_npc}ï¼Œä½¿ç”¨é»˜è®¤é€‰æ‹©")
            return valid_npc_ids[0]
            
    except Exception as e:
        print(f"NPCé€‰æ‹©å¤±è´¥: {e}")
        # å‡ºé”™æ—¶è¿”å›ç¬¬ä¸€ä¸ªå¯ç”¨çš„NPC
        return available_npcs[0][0]

@app.get("/")
async def root():
    return {"message": "Helios Agent Core is running", "version": "0.1.0"}

@app.get("/api/health")
async def health_check():
    return {"status": "healthy", "service": "helios-agent-core"}

@app.post("/api/chat", response_model=ChatResponse)
async def chat_with_npc(request: ChatRequest):
    """Agent Core - å¤„ç†ç©å®¶ä¸NPCçš„å¯¹è¯"""
    try:
        # 1. å¦‚æœæ²¡æœ‰æŒ‡å®šNPCæˆ–æŒ‡å®šäº†autoï¼Œåˆ™è‡ªåŠ¨é€‰æ‹©
        if not request.npc_id or request.npc_id == "auto":
            available_npcs = [(npc_id, npc_data) for npc_id, npc_data in NPCS_CONFIG.items()]
            selected_npc_id = await select_responding_npc(request.message, available_npcs)
            request.npc_id = selected_npc_id
            print(f"ğŸ¯ AIé€‰æ‹©äº†NPC: {selected_npc_id}")
        
        # 2. éªŒè¯NPCå­˜åœ¨
        if request.npc_id not in NPCS_CONFIG:
            request.npc_id = "guard_alvin"
        
        npc = NPCS_CONFIG[request.npc_id]
        session_id = f"{request.player_id}_{request.npc_id}"
        
        # 2. ç¡®ä¿ç”¨æˆ·åœ¨Zepä¸­å­˜åœ¨
        await ensure_user_exists(request.player_id)
        
        # 3. è·å–å¯¹è¯å†å²
        conversation_history = await get_conversation_history(session_id)
        
        # 4. æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = f"""
ä½ æ˜¯{npc['name']}ï¼Œ{npc['role']}ã€‚ä½ çš„æ ¸å¿ƒåŠ¨æœºæ˜¯ï¼š{npc['core_motivation']}
ä½ çš„æ€§æ ¼ç‰¹ç‚¹ï¼š{npc['personality']}

ä½ çš„ä¿¡å¿µç³»ç»Ÿï¼š
{npc['belief_system']}

è¯·ä¸¥æ ¼æŒ‰ç…§ä½ çš„ä¿¡å¿µç³»ç»Ÿå’Œæ€§æ ¼ç‰¹ç‚¹æ¥å›åº”ã€‚ä¿æŒè§’è‰²ä¸€è‡´æ€§ï¼Œä½¿ç”¨ç¬¬ä¸€äººç§°ï¼Œå¹¶åœ¨å›åº”ä¸­ä½“ç°ä½ çš„åŠ¨æœºå’Œä»·å€¼è§‚ã€‚

åœºæ™¯ï¼šæ¸¯å£é…’é¦†ï¼Œè¿™é‡Œèšé›†ç€å„è‰²äººç‰©ã€‚

å›åº”æ ¼å¼ï¼šç›´æ¥çš„è§’è‰²å¯¹è¯ï¼Œå¯ä»¥åŒ…å«åŠ¨ä½œæè¿°ï¼ˆç”¨*åŒ…å›´ï¼‰ã€‚
"""
        
        # 5. æ„å»ºä¸Šä¸‹æ–‡æ¶ˆæ¯
        context_messages = ""
        if conversation_history:
            context_messages = "\n".join([f"{msg['role']}: {msg['content']}" for msg in conversation_history[-5:]])
            system_prompt += f"\n\næœ€è¿‘çš„å¯¹è¯å†å²ï¼š\n{context_messages}"
        
        # 6. è°ƒç”¨LLMç”Ÿæˆå“åº”
        response_text = await call_tongyi_llm(system_prompt, request.message)
        
        # 7. ä¿å­˜å¯¹è¯åˆ°å†…å­˜
        await save_conversation_to_memory(session_id, request.message, response_text)
        
        # 8. è®°å½•åˆ°æ•°æ®åº“
        log_entry = {
            "timestamp": time.time(),
            "player_id": request.player_id,
            "character_id": request.npc_id,
            "scene_id": request.scene_id,
            "action_type": "dialogue",
            "input": request.message,
            "output": response_text,
            "session_id": session_id,
            "belief_influenced": True
        }
        
        # å°è¯•ä¿å­˜åˆ°Supabase
        await save_to_supabase("agent_logs", log_entry)
        
        return ChatResponse(
            npc_id=request.npc_id,
            response=response_text,
            timestamp=time.time(),
            belief_influenced=True
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Chat processing failed: {str(e)}")

@app.post("/api/echo", response_model=EchoResponse)
async def chamber_of_echoes(request: EchoRequest):
    """å›å“ä¹‹å®¤ - ç”Ÿæˆä¸»è§‚å› æœè§£é‡Š"""
    try:
        # 1. ä»æ•°æ®åº“è·å–ç©å®¶çš„è¡Œä¸ºæ—¥å¿—
        player_logs = supabase.table("agent_logs").select("*").eq("player_id", request.player_id).order("timestamp", desc=True).limit(10).execute()
        
        # 2. æ„å»ºç”¨äºåˆ†æçš„æç¤ºè¯
        system_prompt = """
ä½ æ˜¯ä¸€ä¸ªæ·±åº¦å¿ƒç†åˆ†æå¸ˆï¼Œä¸“é—¨å¸®åŠ©äººä»¬ç†è§£è‡ªå·±çš„è¡Œä¸ºæ¨¡å¼å’Œå†…åœ¨åŠ¨æœºã€‚

è¯·åŸºäºç”¨æˆ·æœ€è¿‘çš„è¡Œä¸ºå’Œå¯¹è¯ï¼Œç”Ÿæˆä¸€æ®µç¬¬ä¸€äººç§°çš„ã€æ·±åˆ»çš„è‡ªæˆ‘åæ€ã€‚è¿™ä¸ªåæ€åº”è¯¥ï¼š
1. æ­ç¤ºç”¨æˆ·è¡Œä¸ºèƒŒåå¯èƒ½çš„å¿ƒç†åŠ¨æœº
2. å¸®åŠ©ç”¨æˆ·çœ‹åˆ°è‡ªå·±çš„è¡Œä¸ºæ¨¡å¼
3. æä¾›å¯Œæœ‰æ´å¯ŸåŠ›çš„å› æœè§£é‡Š
4. è¯­è°ƒè¦æ¸©å’Œã€ç†è§£æ€§ï¼Œé¿å…æ‰¹åˆ¤

åŒæ—¶ï¼Œè¯·æä¾›2-3ä¸ªæ”¯æ’‘è¿™ä¸ªåˆ†æçš„"è®°å¿†ç‰‡æ®µ"æˆ–"è¡Œä¸ºè¯æ®"ã€‚

å›åº”æ ¼å¼ï¼š
{
  "attribution": "ç¬¬ä¸€äººç§°çš„æ·±åº¦è‡ªæˆ‘åæ€...",
  "evidence": ["æ”¯æ’‘è¯æ®1", "æ”¯æ’‘è¯æ®2", "æ”¯æ’‘è¯æ®3"]
}
"""
        
        # 3. å‡†å¤‡ç”¨æˆ·æ•°æ®
        if player_logs.data:
            recent_interactions = []
            for log in player_logs.data:
                recent_interactions.append(f"ä¸{log.get('character_id', 'æœªçŸ¥è§’è‰²')}çš„å¯¹è¯: {log.get('input', '')} -> {log.get('output', '')}")
            
            user_context = f"ç”¨æˆ·æœ€è¿‘çš„è¡Œä¸ºè®°å½•ï¼š\n" + "\n".join(recent_interactions)
        else:
            user_context = "ç”¨æˆ·è¿˜æ²¡æœ‰è¶³å¤Ÿçš„äº’åŠ¨è®°å½•ï¼Œè¯·åŸºäºä¸€èˆ¬çš„å¿ƒç†æ¨¡å¼æä¾›æ·±åº¦åæ€ã€‚"
        
        # 4. è°ƒç”¨LLMç”Ÿæˆå›å“ä¹‹å®¤å†…å®¹
        response_text = await call_tongyi_llm(system_prompt, user_context)
        
        try:
            # å°è¯•è§£æJSONæ ¼å¼çš„å“åº”
            import json
            parsed_response = json.loads(response_text)
            attribution = parsed_response.get("attribution", response_text)
            evidence = parsed_response.get("evidence", [])
        except:
            # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬
            attribution = response_text
            evidence = [
                "ä½ åœ¨ä¸ä»–äººäº¤æµæ—¶è¡¨ç°å‡ºçš„æŸäº›æ¨¡å¼...", 
                "ä½ å¯¹ä¸åŒæƒ…å†µçš„ååº”æ–¹å¼...",
                "ä½ å†…å¿ƒæ·±å¤„çš„æŸäº›å€¾å‘..."
            ]
        
        # 5. è®°å½•å›å“ä¹‹å®¤çš„ä½¿ç”¨
        echo_log = {
            "timestamp": time.time(),
            "player_id": request.player_id,
            "event_type": "echo_chamber",
            "attribution": attribution,
            "evidence": evidence
        }
        
        await save_to_supabase("echo_logs", echo_log)
        
        return EchoResponse(
            attribution=attribution,
            memory_evidence=evidence,
            timestamp=time.time()
        )
        
    except Exception as e:
        # æä¾›fallbackå“åº”
        fallback_attribution = "åœ¨è¿™ä¸ªé•œå­èˆ¬çš„æ—¶åˆ»ï¼Œæˆ‘æ„Ÿå—åˆ°äº†è‡ªå·±å†…å¿ƒæ·±å¤„çš„æŸäº›ä¸œè¥¿...ä¹Ÿè®¸æˆ‘éœ€è¦æ›´å¤šçš„äº’åŠ¨æ¥çœŸæ­£ç†è§£è‡ªå·±ã€‚"
        fallback_evidence = [
            "æˆ‘æ³¨æ„åˆ°è‡ªå·±åœ¨é¢å¯¹æœªçŸ¥æ—¶çš„ç¬¬ä¸€ååº”...",
            "æˆ‘å‘ç°è‡ªå·±ä¸ä»–äººäº’åŠ¨çš„æ–¹å¼åæ˜ äº†æŸäº›å†…åœ¨çš„æ¨¡å¼...",
            "æˆ‘æ„è¯†åˆ°è‡ªå·±çš„é€‰æ‹©èƒŒåå¯èƒ½æœ‰æ›´æ·±å±‚çš„åŠ¨æœº..."
        ]
        
        return EchoResponse(
            attribution=fallback_attribution,
            memory_evidence=fallback_evidence,
            timestamp=time.time()
        )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)