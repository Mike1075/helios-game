#!/usr/bin/env python3
"""
ç›´æ¥æµ‹è¯•Vercel AI GatewayèŠå¤©åŠŸèƒ½
"""

import requests
import json

def test_chat_call():
    """
    æµ‹è¯•å®é™…çš„èŠå¤©è°ƒç”¨
    """
    API_KEY = "EtMyP4WaMfdkxizkutRrJT1j"
    
    # åŸºäº405å“åº”ï¼Œè¿™ä¸ªç«¯ç‚¹å­˜åœ¨ï¼Œå°è¯•POSTè¯·æ±‚
    CHAT_URL = "https://ai-gateway.vercel.sh/v1/ai/chat/completions"
    
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    
    # æµ‹è¯•ä¸åŒæ¨¡å‹åç§°æ ¼å¼
    models_to_test = [
        "gpt-4o-mini",
        "openai/gpt-4o-mini", 
        "gpt-4o",
        "anthropic/claude-3-5-sonnet",
        "claude-3-5-sonnet"
    ]
    
    for model in models_to_test:
        print(f"\næµ‹è¯•æ¨¡å‹: {model}")
        print("=" * 50)
        
        payload = {
            "model": model,
            "messages": [
                {"role": "user", "content": "Hello! Please respond with just 'Hi there' and nothing else."}
            ],
            "max_tokens": 10
        }
        
        try:
            response = requests.post(CHAT_URL, headers=headers, json=payload)
            print(f"çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                print(f"âœ… æˆåŠŸ! å“åº”: {result['choices'][0]['message']['content']}")
                return model, CHAT_URL  # è¿”å›ç¬¬ä¸€ä¸ªæˆåŠŸçš„æ¨¡å‹
            else:
                print(f"âŒ å¤±è´¥: {response.text[:200]}")
                
        except Exception as e:
            print(f"âŒ å¼‚å¸¸: {e}")
    
    print("\næ‰€æœ‰æ¨¡å‹æµ‹è¯•å®Œæ¯•")
    return None, None

def test_streaming_chat():
    """
    æµ‹è¯•æµå¼èŠå¤©
    """
    API_KEY = "EtMyP4WaMfdkxizkutRrJT1j"
    CHAT_URL = "https://ai-gateway.vercel.sh/v1/ai/chat/completions"
    
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": "gpt-4o-mini",
        "messages": [
            {"role": "user", "content": "Count from 1 to 5"}
        ],
        "max_tokens": 20,
        "stream": True
    }
    
    print("\næµ‹è¯•æµå¼å“åº”:")
    print("=" * 50)
    
    try:
        response = requests.post(CHAT_URL, headers=headers, json=payload, stream=True)
        print(f"çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code == 200:
            print("âœ… æµå¼å“åº”å¼€å§‹:")
            for line in response.iter_lines():
                if line:
                    line_str = line.decode('utf-8')
                    print(f"  {line_str}")
                    if 'data: [DONE]' in line_str:
                        break
        else:
            print(f"âŒ æµå¼è¯·æ±‚å¤±è´¥: {response.text}")
            
    except Exception as e:
        print(f"âŒ æµå¼è¯·æ±‚å¼‚å¸¸: {e}")

if __name__ == "__main__":
    print("Vercel AI Gateway èŠå¤©æµ‹è¯•å·¥å…·")
    print("=" * 50)
    
    # æµ‹è¯•æ™®é€šèŠå¤©
    working_model, working_url = test_chat_call()
    
    if working_model:
        print(f"\nğŸ‰ æ‰¾åˆ°å¯ç”¨é…ç½®:")
        print(f"  æ¨¡å‹: {working_model}")
        print(f"  ç«¯ç‚¹: {working_url}")
        
        # æµ‹è¯•æµå¼èŠå¤©
        test_streaming_chat()
        
        # ä¿å­˜é…ç½®
        config = {
            "working_model": working_model,
            "working_url": working_url,
            "api_key": "EtMyP4WaMfdkxizkutRrJT1j"
        }
        
        with open("../docs/working-ai-config.json", "w") as f:
            json.dump(config, f, indent=2)
        print(f"\nâœ… å·¥ä½œé…ç½®å·²ä¿å­˜åˆ°: ../docs/working-ai-config.json")
    else:
        print("\nâŒ æœªæ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹é…ç½®")