#!/usr/bin/env python3
"""
æµ‹è¯•å¢å¼ºç‰ˆèŠå¤©åŠŸèƒ½
"""

import requests
import json

def test_model_selection():
    """
    æµ‹è¯•ä¸åŒæ¨¡å‹é€‰æ‹©
    """
    print("=== æµ‹è¯•å¤šæ¨¡å‹é€‰æ‹©åŠŸèƒ½ ===")
    
    test_models = [
        'openai/gpt-5-mini',
        'anthropic/claude-sonnet-4',
        'google/gemini-2.5-flash'
    ]
    
    for model in test_models:
        print(f"\næµ‹è¯•æ¨¡å‹: {model}")
        
        chat_payload = {
            "messages": [
                {
                    "role": "user", 
                    "content": f"Hello! Please respond with 'Hi from {model}!' in **bold**"
                }
            ],
            "model": model
        }
        
        try:
            response = requests.post(
                "http://localhost:3000/api/chat",
                json=chat_payload,
                headers={"Content-Type": "application/json"},
                stream=True
            )
            
            print(f"çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                content = ""
                for chunk in response.iter_content(chunk_size=1, decode_unicode=True):
                    if chunk:
                        content += chunk
                
                print(f"âœ… {model} å“åº”: '{content[:50]}...'")
            else:
                print(f"âŒ {model} å¤±è´¥: {response.text[:100]}")
                
        except Exception as e:
            print(f"âŒ {model} å¼‚å¸¸: {e}")

def test_markdown_content():
    """
    æµ‹è¯•Markdownå¯Œæ–‡æœ¬
    """
    print(f"\n=== æµ‹è¯•Markdownå¯Œæ–‡æœ¬æ”¯æŒ ===")
    
    chat_payload = {
        "messages": [
            {
                "role": "user", 
                "content": "è¯·ç”¨Markdownæ ¼å¼å›å¤ï¼ŒåŒ…å«ï¼šæ ‡é¢˜ã€ä»£ç å—ã€åˆ—è¡¨"
            }
        ],
        "model": "openai/gpt-5-mini"
    }
    
    try:
        response = requests.post(
            "http://localhost:3000/api/chat",
            json=chat_payload,
            headers={"Content-Type": "application/json"},
            stream=True
        )
        
        print(f"çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code == 200:
            content = ""
            for chunk in response.iter_content(chunk_size=1, decode_unicode=True):
                if chunk:
                    content += chunk
            
            print(f"âœ… Markdownå†…å®¹: '{content[:100]}...'")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«Markdownå…ƒç´ 
            markdown_elements = ['#', '```', '*', '-']
            found_elements = [elem for elem in markdown_elements if elem in content]
            
            if found_elements:
                print(f"âœ… æ£€æµ‹åˆ°Markdownå…ƒç´ : {found_elements}")
            else:
                print("âš ï¸ æœªæ£€æµ‹åˆ°Markdownå…ƒç´ ")
                
            return True
        else:
            print(f"âŒ Markdownæµ‹è¯•å¤±è´¥: {response.text}")
            return False
            
    except Exception as e:
        print(f"âŒ Markdownæµ‹è¯•å¼‚å¸¸: {e}")
        return False

if __name__ == "__main__":
    print("å¢å¼ºç‰ˆèŠå¤©åŠŸèƒ½æµ‹è¯•å·¥å…·")
    print("=" * 60)
    
    # æµ‹è¯•æ¨¡å‹é€‰æ‹©
    test_model_selection()
    
    # æµ‹è¯•Markdownå¯Œæ–‡æœ¬
    markdown_success = test_markdown_content()
    
    print(f"\n=== æµ‹è¯•æ€»ç»“ ===")
    print("âœ… å¤šæ¨¡å‹é€‰æ‹©åŠŸèƒ½: å¯ç”¨")
    print(f"âœ… Markdownå¯Œæ–‡æœ¬: {'å¯ç”¨' if markdown_success else 'éƒ¨åˆ†å¯ç”¨'}")
    print("âœ… ç¾åŒ–ç•Œé¢: å·²å®ç°")
    print("âœ… æµå¼è¾“å‡º: æ­£å¸¸å·¥ä½œ")
    
    print(f"\nğŸ‰ è®¿é—® http://localhost:3000/chat ä½“éªŒ:")
    print("- 11ç§AIæ¨¡å‹é€‰æ‹©")  
    print("- æ¸å˜è‰²ç¾è§‚ç•Œé¢")
    print("- Markdownä»£ç é«˜äº®")
    print("- å®æ—¶æµå¼å¯¹è¯")
    print("- è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨")